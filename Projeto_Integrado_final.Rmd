---
title: "Projeto Final"
author: "Caio Emerson Tiago Vinicius"
date: '2023-06-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pacotes}
library(tidyverse)
library(ggplot2)
library(summarytools)
library(gmodels)
library(dplyr)
library(fastDummies)
```


```{r leitura}

# nao mostrar os resultados na notacao cientifica
options(scipen = 999)

library(readr)
df <- read_csv("./data/train.csv")
```

### Mudar as variaveis quantitativas em qualitativas

```{r}
df$`023c68873b` <- factor(df$`023c68873b`)
df$`06888ceac9` <- factor(df$`06888ceac9`)
df$`361f93f4d1` <- factor(df$`361f93f4d1`)
df$`384bec5dd1` <- factor(df$`384bec5dd1`)
df$`7cb7913148` <- factor(df$`7cb7913148`, ordered=TRUE)
df$`8d0606b150` <- factor(df$`8d0606b150`)
df$`91145d159d` <- factor(df$`91145d159d`)
df$`9a575e82a4` <- factor(df$`9a575e82a4`)
df$`b835dfe10f` <- factor(df$`b835dfe10f`)
df$`e16e640635` <- factor(df$`e16e640635`)
df$`f1f0984934` <- factor(df$`f1f0984934`)

```

### Analise descritiva

Conhecer as variaveis

```{r descritiva}
# medidas resumo
summary(df)
```

### Grafico univariado

```{r grafico1}
# grafico de uma variavel quantitativa
qplot(x=df$target)
```

```{r grafico2}
# grafico de uma variavel qualitativa
qplot(x=df$`7cb7913148`, geom = "bar")
```

```{r grafico2}
# grafico de uma variavel qualitativa
qplot(x=df$`8f5f7c556a`, geom = "bar")
```

```{r grafico5}
boxplot(df$target ~ df$`7cb7913148`)
```



```{r}
dadosQuali <- df %>%
  select(`023c68873b`,`06888ceac9`,`361f93f4d1`,`384bec5dd1`,`7cb7913148`,`8d0606b150`,`91145d159d`,`9a575e82a4`,`b835dfe10f`,`e16e640635`,`f1f0984934`)

dadosQuant <- df %>%
  select(-c(id,target,`023c68873b`,`06888ceac9`,`361f93f4d1`,`384bec5dd1`,`7cb7913148`,`8d0606b150`,`91145d159d`,`9a575e82a4`,`b835dfe10f`,`e16e640635`,`f1f0984934`))

target <- df$target

```

```{r cnt}
summary(target)
```

ntile() é uma função do dplyr para criar categorias usando os quartis.

```{r faixa}

df1 <- df

# Criar a variavel faixa de cnt
df1$fxtarget_num <- ntile(df$target, 4)  
df1$fxtarget_cat <- factor(df1$fxtarget_num, levels=c(1,2,3,4),labels = c(labels=c("[ -0.2398 a 0.5031]", "(0.5031 a 0.9838]",
                                                                                    "(0.9838 a 1.6609]",  "(1.6609 a 61.3261]")))
df1$fxtarget_cat <- factor(df1$fxtarget_cat, ordered =TRUE)
freq(df1$fxtarget_cat)

```

```{r tabela1a}
df1$quali_7cb7913148 <- factor(df1$`7cb7913148`)

CrossTable(df1$fxtarget_cat,df1$quali_7cb7913148, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```
```{r tabela1a}
df1$quali_06888ceac9 <- factor(df1$`06888ceac9`)

CrossTable(df1$fxtarget_cat,df1$quali_06888ceac9, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```
```{r tabela1a}
df1$quali_384bec5dd1 <- factor(df1$`384bec5dd1`)

CrossTable(df1$fxtarget_cat,df1$quali_384bec5dd1, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```

```{r tabela1a}
df1$quali_9a575e82a4 <- factor(df1$`9a575e82a4`)

CrossTable(df1$fxtarget_cat,df1$quali_9a575e82a4, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```


```{r grafico15}
# frequencia de season
freq_total <- df1 %>%
  select(fxtarget_cat) %>%
  group_by(fxtarget_cat) %>%
  summarise(obs = n()) %>%
  mutate(freq = obs/sum(obs)*100) %>%
  mutate(quali_7cb7913148 = ifelse(fxtarget_cat =="[ -0.2398 a 0.5031]", "1",
                               ifelse(fxtarget_cat =="(0.5031 a 0.9838]","2",
                                      ifelse(fxtarget_cat =="(0.9838 a 1.6609]","3","4")))) %>%
  mutate(fxtarget_num=5) %>%
  relocate(fxtarget_num, .before = fxtarget_cat) %>%
  relocate(quali_7cb7913148, .after = fxtarget_cat) 

                                                                                   

# frequencia de season por faixa de target
freq_fxtarget <- df1 %>%
  select(fxtarget_num, fxtarget_cat,quali_7cb7913148) %>%
  group_by(fxtarget_num, fxtarget_cat,quali_7cb7913148) %>%
  summarise(obs = n()) %>%
  mutate(freq = obs/sum(obs)*100)
  
# append  
freq <- rbind(freq_fxtarget,freq_total)  


ggplot(freq, aes(x = fxtarget_num, y = freq, fill = quali_7cb7913148, label = round(freq, 1))) +
  geom_col() +
  geom_text(position = position_stack(vjust = 0.5)) +
  labs(title= "Demanda de bikes segundo a estacao do ano",
            x= "Target", y="%") 
  
```

```{r}

# names(dadosQuali)
names(dadosQuant)


```

```{r grafico33}
# grafico de duas variaveis quantitativas 
qplot(x=df$`8de0382f02`, y=df$target)
```
```{r normalizando}
# Normalização para o intervalo [0, 1]
df_norm <- dadosQuant %>%
  # select(-target) %>%
  mutate(across(everything(), ~(. - min(.)) / (max(.) - min(.))))
```


### Análise de correlacao de Pearson

Escala das Variáveis: Se as variáveis que você está analisando têm escalas muito diferentes, a normalização pode ser útil. Por exemplo, se uma variável é a idade (variando de 0 a 100) e outra é o salário anual (variando de 0 a milhões), os resultados da análise bivariada podem ser afetados pela diferença de escalas.

Distribuição dos Dados: Se os dados têm uma distribuição muito inclinada ou assimétrica, às vezes é útil normalizar ou transformar os dados para fazer com que sua distribuição seja mais próxima da normal. Isso pode ser especialmente importante se você planeja usar métodos estatísticos que assumem uma distribuição normal.

Técnicas de Análise: Algumas técnicas de análise bivariada, como a correlação de Pearson, são sensíveis à escala dos dados. Nesses casos, a normalização pode ser necessária para obter resultados significativos.

Interpretação e Visualização: Em alguns casos, a normalização pode facilitar a interpretação dos resultados e a criação de visualizações mais eficazes.

```{r correlacao}
# selecionar somente as variaveis quantitativas

df_corr <- cbind(df_norm,target)

correlacao <- cor(df_corr)
correlacao

mc <- correlacao
```


```{r grafico13}
library(corrplot)
#corrplot(mc)
corrplot(mc, type="full", method="number")
```


```{r criar dummies}
# criar variaveis dummies das variaveis preditoras qualitativas
var_dummies <- dummy_cols(dadosQuali, select_columns = c("023c68873b","361f93f4d1","7cb7913148","8d0606b150", "91145d159d","b835dfe10f", "e16e640635", "f1f0984934"),
           remove_first_dummy = TRUE,
           remove_selected_columns = TRUE)
```


```{r target}

df_modelo <- cbind(df_norm,var_dummies,target)

```

### Modelo de Regressão Linear Múltipla
### Dividir a amostra em treino e validação

```{r amostras}

#Dividir em duas amostras
set.seed(2021)
train <- sample(nrow(df_modelo), 0.7*nrow(df_modelo), replace = FALSE)
TrainSet <- df_modelo[train,]
ValidSet <- df_modelo[-train,]

```

### Comparar a variável resposta nas duas amostras

```{r amostra1}
summary(TrainSet$target)

```


```{r amostra2}
summary(ValidSet$target)
```
### Rodar o modelo
```{r modelo}
modelo <- lm(target ~ ., data = TrainSet)
summary(modelo)
```

```{r stepwise acelerada }
# # install.packages("MASS")
# # Carregar o pacote MASS
# library(MASS)
# 
# # Realizar a seleção stepwise acelerada
# modelo_stepwise <- stepAIC(modelo, trace = 1,
#                            steps = 2, # Número máximo de etapas a serem tomadas
#                            k = 2) # Parâmetro de penalização (padrão é 2, equivalente ao AIC)

```


```{r previsao1}

TrainSet$Val_pred <- predict(modelo) 
TrainSet$residuo  <- resid(modelo)
TrainSet$rp <- rstandard(modelo)


```


```{r analise}
df_analise <- TrainSet %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse1}
# Erro quadratico medio na amostra de treino
mse <- mean((TrainSet$target - TrainSet$Val_pred)^2)
sqrt(mse)

```
### Análise dos resíduos do modelo

```{r residuo1}
plot(predict(modelo),TrainSet$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```
```{r normalidade1}
qqnorm(residuals(modelo), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo))
```


```{r excluir_outlier1}

#Excluir os outliers
TrainSet_1 <-filter(TrainSet,TrainSet$rp>=-2&TrainSet$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_1$Val_pred = NULL
TrainSet_1$residuo = NULL
TrainSet_1$rp = NULL
```

### Rodar o modelo
```{r modelo}
modelo2 <- lm(target ~ ., data = TrainSet_1)
summary(modelo2)
```


```{r previsao2}

TrainSet_1$Val_pred <- predict(modelo2) 
TrainSet_1$residuo  <- resid(modelo2)
TrainSet_1$rp <- rstandard(modelo2)

```

```{r analise2}
df_analise2 <- TrainSet_1 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse1}
# Erro quadratico medio na amostra de treino
mse2 <- mean((TrainSet_1$target - TrainSet_1$Val_pred)^2)
sqrt(mse2)

```
### Análise dos resíduos do modelo

```{r residuo2}
plot(predict(modelo2),TrainSet_1$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```

```{r normalidade2}
qqnorm(residuals(modelo2), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo2))
```
```{r excluir_outlier2}

#Excluir os outliers
TrainSet_2 <-filter(TrainSet_1,TrainSet_1$rp>=-2&TrainSet_1$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_2$Val_pred = NULL
TrainSet_2$residuo = NULL
TrainSet_2$rp = NULL
```

### Rodar o modelo
```{r modelo3}
modelo3 <- lm(target ~ ., data = TrainSet_2)
summary(modelo3)
```

```{r previsao3}

TrainSet_2$Val_pred <- predict(modelo3) 
TrainSet_2$residuo  <- resid(modelo3)
TrainSet_2$rp <- rstandard(modelo3)

```

```{r analise3}
df_analise3 <- TrainSet_2 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse3}
# Erro quadratico medio na amostra de treino
mse3 <- mean((TrainSet_2$target - TrainSet_2$Val_pred)^2)
sqrt(mse3)

```
### Análise dos resíduos do modelo

```{r residuo3}
plot(predict(modelo3),TrainSet_2$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```

```{r normalidade3}
qqnorm(residuals(modelo3), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo3))
```

```{r excluir_outlier3}

#Excluir os outliers
TrainSet_3 <-filter(TrainSet_2,TrainSet_2$rp>=-2&TrainSet_2$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_3$Val_pred = NULL
TrainSet_3$residuo = NULL
TrainSet_3$rp = NULL
```

### Rodar o modelo
```{r modelo4}
modelo4 <- lm(target ~ ., data = TrainSet_3)
summary(modelo3)
```

```{r previsao4}

TrainSet_3$Val_pred <- predict(modelo4) 
TrainSet_3$residuo  <- resid(modelo4)
TrainSet_3$rp <- rstandard(modelo4)

```

```{r analise4}
df_analise4 <- TrainSet_3 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse4}
# Erro quadratico medio na amostra de treino
mse4 <- mean((TrainSet_3$target - TrainSet_3$Val_pred)^2)
sqrt(mse4)

```
### Análise dos resíduos do modelo

```{r residuo4}
plot(predict(modelo4),TrainSet_3$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```
```{r normalidade4}
qqnorm(residuals(modelo4), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo4))
```


##---------------------------------------------------------------------------------------
##                           AMOSTRA DE VALIDACAO
##---------------------------------------------------------------------------------------


```{r amostra_validacao}

# Amostra de validacao

target_pred <- predict(modelo4,interval = "prediction", level = 0.95,
                    newdata = ValidSet, se.fit = T) 

target_pred1 <-target_pred$fit
ValidSet_pred=cbind(ValidSet,target_pred1)
```


```{r residuo_validacao}
# Residuo na amostra de validacao
residuo_valid <- ValidSet_pred$target - ValidSet_pred$fit
hist(residuo_valid)
qqnorm(residuo_valid, ylab="Res?duos",xlab="Quantis te?ricos",main="")
qqline(residuo_valid)
```



```{r rmse_validacao}

# Erro quadratico medio na amostra de validacao
mse2 <- mean((ValidSet_pred$target - ValidSet_pred$fit)^2)
sqrt(mse2)
```
```{r}
library(ggplot2)

# Convertendo as previsões para um data.frame
pred_df <- as.data.frame(target_pred$fit)

# Adicionando a variável independente ou índice ao data.frame (se necessário)
# Substitua variavel_independente pelo nome da sua variável independente ou use um índice sequencial.
pred_df$x <- 1:7493

# Criando o gráfico com apenas as primeiras 10 previsões
ggplot(pred_df[300:400, ], aes(x = x, y = fit)) +
  geom_point(aes(y = ValidSet$target[300:400]), color = 'blue') + # Pontos dos dados reais
  geom_line(aes(y = fit), color = 'black') + # Linha dos valores ajustados
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) + # Área de intervalo de predição
  labs(x = "Variável Independente", y = "Target", title = "Valores Ajustados com Intervalo de Predição para as Primeiras 10 Observações")


```
```{r}
# Fazer previsões nos dados de validação
predictions <- predict(modelo2, newdata = ValidSet)
```

```{r}
# Calculando o MSE
mse <- mean((ValidSet$target - predictions)^2)

# Calculando o RMSE
rmse <- sqrt(mse)

# Calculando o MAE
mae <- mean(abs(ValidSet$target - predictions))

# Imprimindo os resultados
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")

# Calcular a soma dos quadrados dos resíduos (SS_res)
SS_res <- sum((ValidSet$target - predictions)^2)

# Calcular a soma total dos quadrados (SS_tot)
SS_tot <- sum((ValidSet$target - mean(ValidSet$target))^2)

# Calcular o R² nos dados de validação
R2_validation <- 1 - (SS_res / SS_tot)

# Imprimir o R²
cat("R² nos dados de validação:", R2_validation, "\n")
```


