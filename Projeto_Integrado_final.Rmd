---
title: "Projeto Final"
author: "Caio Emerson Tiago Vinicius"
date: '2023-06-17'
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r pacotes}
library(tidyverse)
library(ggplot2)
library(summarytools)
library(gmodels)
library(dplyr)
library(fastDummies)
```


```{r leitura}

# nao mostrar os resultados na notacao cientifica
options(scipen = 999)

library(readr)
df <- read_csv("./data/train.csv")
```

```{r}
# Nomes das colunas que você quer renomear
colunas_para_renomear <- setdiff(names(df), c("id", "target"))

# Número de colunas para renomear
num_colunas <- length(colunas_para_renomear)

# Inicializando o dicionário
dicionario <- list()

# Renomear as colunas para x1, x2, x3, ... e criar o dicionario
for (i in 1:num_colunas) {
    colname <- colunas_para_renomear[i]
    new_colname <- paste("x", i, sep="")
    
    # Adicionando ao dicionário
    dicionario[[new_colname]] <- colname
    
    # Renomeando a coluna
    names(df)[names(df) == colname] <- new_colname
}

# Visualizando o dicionario
# dicionario
```



### Mudar as variaveis quantitativas em qualitativas

```{r}
df$x2 <- factor(df$x2)
df$x5 <- factor(df$x5)
df$x27 <- factor(df$x27)
df$x28 <- factor(df$x28)
df$x53 <- factor(df$x53, ordered=TRUE)
df$x59 <- factor(df$x59)
df$x62 <- factor(df$x62)
df$x67 <- factor(df$x67)
df$x78 <- factor(df$x78)
df$x91 <- factor(df$x91)
df$x100 <- factor(df$x100)

```


### Analise descritiva

Conhecer as variaveis

```{r descritiva}
# medidas resumo
summary(df)
```

### Grafico univariado

```{r grafico1}
# grafico de uma variavel quantitativa
qplot(x=df$target)
```

```{r grafico2}
# grafico de uma variavel qualitativa
qplot(x=df$x53, geom = "bar")
```

```{r grafico2}
# grafico de uma variavel qualitativa
qplot(x=df$x61, geom = "bar")
```

```{r grafico5}
boxplot(df$target ~ df$x53)
```



```{r}
dadosQuali <- df %>%
  select(x2,x5,x27,x28,x53,x59,x62,x67,x78,x91,x100)

dadosQuant <- df %>%
  select(-c(id,target,x2,x5,x27,x28,x53,x59,x62,x67,x78,x91,x100))

target <- df$target

```

```{r cnt}
summary(target)
```

ntile() é uma função do dplyr para criar categorias usando os quartis.

```{r faixa}

df1 <- df

# Criar a variavel faixa de cnt
df1$fxtarget_num <- ntile(df$target, 4)  
df1$fxtarget_cat <- factor(df1$fxtarget_num, levels=c(1,2,3,4),labels = c(labels=c("[ -0.2398 a 0.5031]", "(0.5031 a 0.9838]",
                                                                                    "(0.9838 a 1.6609]",  "(1.6609 a 61.3261]")))
df1$fxtarget_cat <- factor(df1$fxtarget_cat, ordered =TRUE)
freq(df1$fxtarget_cat)

```

```{r tabela1a}
df1$quali_x53 <- factor(df1$x53)

CrossTable(df1$fxtarget_cat,df1$quali_x53, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```
```{r tabela1a}
df1$quali_x5 <- factor(df1$x5)

CrossTable(df1$fxtarget_cat,df1$quali_x5, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```
```{r tabela1a}
df1$quali_x28 <- factor(df1$x28)

CrossTable(df1$fxtarget_cat,df1$quali_x28, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```

```{r tabela1a}
df1$quali_9a575e82a4 <- factor(df1$x67)

CrossTable(df1$fxtarget_cat,df1$quali_9a575e82a4, prop.r = FALSE, prop.c = FALSE, prop.t = FALSE,
           prop.chisq = FALSE,chisq = FALSE)

```


```{r grafico15}
# frequencia de season
freq_total <- df1 %>%
  select(fxtarget_cat) %>%
  group_by(fxtarget_cat) %>%
  summarise(obs = n()) %>%
  mutate(freq = obs/sum(obs)*100) %>%
  mutate(quali_x53 = ifelse(fxtarget_cat =="[ -0.2398 a 0.5031]", "1",
                               ifelse(fxtarget_cat =="(0.5031 a 0.9838]","2",
                                      ifelse(fxtarget_cat =="(0.9838 a 1.6609]","3","4")))) %>%
  mutate(fxtarget_num=5) %>%
  relocate(fxtarget_num, .before = fxtarget_cat) %>%
  relocate(quali_x53, .after = fxtarget_cat) 

                                                                                   

# frequencia de season por faixa de target
freq_fxtarget <- df1 %>%
  select(fxtarget_num, fxtarget_cat,quali_x53) %>%
  group_by(fxtarget_num, fxtarget_cat,quali_x53) %>%
  summarise(obs = n()) %>%
  mutate(freq = obs/sum(obs)*100)
  
# append  
freq <- rbind(freq_fxtarget,freq_total)  


ggplot(freq, aes(x = fxtarget_num, y = freq, fill = quali_x53, label = round(freq, 1))) +
  geom_col() +
  geom_text(position = position_stack(vjust = 0.5)) +
  labs(title= "Demanda de bikes segundo a estacao do ano",
            x= "Target", y="%") 
  
```

```{r}

# names(dadosQuali)
names(dadosQuant)


```

```{r grafico33}
# grafico de duas variaveis quantitativas 
qplot(x=df$x60, y=df$target)
```

```{r}
# Função para detectar se uma coluna tem outliers
detect_outliers <- function(column) {
  Q1 <- quantile(column, 0.25)
  Q3 <- quantile(column, 0.75)
  IQR <- Q3 - Q1
  lower_bound <- Q1 - 1.5 * IQR
  upper_bound <- Q3 + 1.5 * IQR
  return(any(column < lower_bound | column > upper_bound))
}

# Função para transformar uma coluna numérica em categorias
transform_to_categories <- function(column) {
  n <- length(column)
  k <- round(1 + 3.322 * log10(n)) # número de bins com base na fórmula de Sturges
  return(cut(column, breaks = k, labels = FALSE))
}
```

```{r}

```


```{r}
# dadosQuant1 = dadosQuant

# Processando cada coluna do dataset
for (col_name in names(dadosQuant)) {
  if (is.numeric(dadosQuant[[col_name]])) {
    if (detect_outliers(dadosQuant[[col_name]])) {
      dadosQuali[[col_name]] <- as.factor(transform_to_categories(dadosQuant[[col_name]]))
      dadosQuant[[col_name]] <- NULL
      cat(sprintf("Transformed column '%s' into categories\n", col_name))
    }
  }
}
```



```{r normalizando}
# Normalização para o intervalo [0, 1]
df_norm <- dadosQuant %>%
  # select(-target) %>%
  mutate(across(everything(), ~(. - min(.)) / (max(.) - min(.))))
```


### Análise de correlacao de Pearson

Escala das Variáveis: Se as variáveis que você está analisando têm escalas muito diferentes, a normalização pode ser útil. Por exemplo, se uma variável é a idade (variando de 0 a 100) e outra é o salário anual (variando de 0 a milhões), os resultados da análise bivariada podem ser afetados pela diferença de escalas.

Distribuição dos Dados: Se os dados têm uma distribuição muito inclinada ou assimétrica, às vezes é útil normalizar ou transformar os dados para fazer com que sua distribuição seja mais próxima da normal. Isso pode ser especialmente importante se você planeja usar métodos estatísticos que assumem uma distribuição normal.

Técnicas de Análise: Algumas técnicas de análise bivariada, como a correlação de Pearson, são sensíveis à escala dos dados. Nesses casos, a normalização pode ser necessária para obter resultados significativos.

Interpretação e Visualização: Em alguns casos, a normalização pode facilitar a interpretação dos resultados e a criação de visualizações mais eficazes.

```{r correlacao}
# selecionar somente as variaveis quantitativas

df_corr <- cbind(df_norm,target)

correlacao <- cor(df_corr)
correlacao

mc <- correlacao
```


```{r grafico13}
library(corrplot)
#corrplot(mc)
corrplot(mc, type="full", method="number")
```


```{r criar dummies}

# Criar uma lista de todas as colunas categóricas, exceto 'x5'
columns_to_dummy <- setdiff(names(dadosQuali), c("x5", "x28", "x67"))

# criar variaveis dummies das variaveis preditoras qualitativas
var_dummies <- dummy_cols(dadosQuali, select_columns = columns_to_dummy,
           remove_first_dummy = TRUE,
           remove_selected_columns = TRUE)
```


```{r target}

df_modelo <- cbind(df_norm,var_dummies,target)

```

### Modelo de Regressão Linear Múltipla
### Dividir a amostra em treino e validação

```{r amostras}

#Dividir em duas amostras
set.seed(1010)
train <- sample(nrow(df_modelo), 0.7*nrow(df_modelo), replace = FALSE)
TrainSet <- df_modelo[train,]
ValidSet <- df_modelo[-train,]

```

### Comparar a variável resposta nas duas amostras

```{r amostra1}
summary(TrainSet$target)

```


```{r amostra2}
summary(ValidSet$target)
```
### Rodar o modelo
```{r modelo}
modelo_inicial <- lm(target ~ ., data = TrainSet)
summary(modelo_inicial)
```
# Rodar apenas se preferir a abordagem de eliminar os p-value

```{r variaveis_significativas }
# Obter um sumário do modelo
summary_modelo <- summary(modelo_inicial)

# Obter os p-values
p_values <- summary_modelo$coefficients[, 4]

# Selecionar os nomes das variáveis com p-values < 0.05
variaveis_significativas <- names(p_values)[p_values < 0.05]

# Remover a interceptação (se estiver presente)
variaveis_significativas <- variaveis_significativas[variaveis_significativas != "(Intercept)"]

# correção de erros
variaveis_significativas <- str_replace_all(variaveis_significativas,"x51","x5")
# variaveis_significativas <- str_replace_all(variaveis_significativas,"x281","x28")
variaveis_significativas <- str_replace_all(variaveis_significativas,"x671","x67")

# Adicionar a coluna target ao vetor de colunas significativas
colunas_para_manter <- c("target", variaveis_significativas)

# Crie um novo conjunto de dados com apenas as colunas significativas
# novo_TrainSet <- TrainSet[, colunas_para_manter]
novo_TrainSet <- TrainSet

# Crie um novo conjunto de dados com apenas as colunas significativas
# novo_ValidSet <- ValidSet[, colunas_para_manter]
novo_ValidSet <- ValidSet

# Aplique o modelo de regressão linear usando o novo conjunto de dados
novo_modelo <- lm(target ~ ., data = novo_TrainSet)

# Veja o resumo do novo modelo
summary(novo_modelo)
```


```{r previsao1}

novo_TrainSet$Val_pred <- predict(novo_modelo) 
novo_TrainSet$residuo  <- resid(novo_modelo)
novo_TrainSet$rp <- rstandard(novo_modelo)

```


```{r rmse1}
# Erro quadratico medio na amostra de treino
mse <- mean((novo_TrainSet$target - novo_TrainSet$Val_pred)^2)
sqrt(mse)

```
### Análise dos resíduos do modelo

```{r residuo1}
plot(predict(novo_modelo),novo_TrainSet$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```
```{r normalidade1}
qqnorm(residuals(novo_modelo), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(novo_modelo))
```


```{r excluir_outlier1}

#Excluir os outliers
TrainSet_1 <-filter(novo_TrainSet,novo_TrainSet$rp>=-2&novo_TrainSet$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_1$Val_pred = NULL
TrainSet_1$residuo = NULL
TrainSet_1$rp = NULL
```

### Rodar o modelo
```{r modelo}
modelo1 <- lm(target ~ ., data = TrainSet_1)
summary(modelo1)
```


```{r previsao2}

TrainSet_1$Val_pred <- predict(modelo1) 
TrainSet_1$residuo  <- resid(modelo1)
TrainSet_1$rp <- rstandard(modelo1)

```

```{r analise2}
df_analise1 <- TrainSet_1 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse1}
# Erro quadratico medio na amostra de treino
mse1 <- mean((TrainSet_1$target - TrainSet_1$Val_pred)^2)
sqrt(mse1)

```
### Análise dos resíduos do modelo

```{r residuo2}
plot(predict(modelo1),TrainSet_1$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```

```{r normalidade2}
qqnorm(residuals(modelo1), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo1))
```
```{r excluir_outlier2}

#Excluir os outliers
TrainSet_2 <-filter(TrainSet_1,TrainSet_1$rp>=-2&TrainSet_1$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_2$Val_pred = NULL
TrainSet_2$residuo = NULL
TrainSet_2$rp = NULL
```

### Rodar o modelo
```{r modelo3}
modelo2 <- lm(target ~ ., data = TrainSet_2)
summary(modelo2)
```

```{r previsao3}

TrainSet_2$Val_pred <- predict(modelo2) 
TrainSet_2$residuo  <- resid(modelo2)
TrainSet_2$rp <- rstandard(modelo2)

```

```{r analise3}
df_analise2 <- TrainSet_2 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse3}
# Erro quadratico medio na amostra de treino
mse2 <- mean((TrainSet_2$target - TrainSet_2$Val_pred)^2)
sqrt(mse2)

```
### Análise dos resíduos do modelo

```{r residuo3}
plot(predict(modelo2),TrainSet_2$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```

```{r normalidade3}
qqnorm(residuals(modelo2), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo2))
```

```{r excluir_outlier3}

#Excluir os outliers
TrainSet_3 <-filter(TrainSet_2,TrainSet_2$rp>=-2&TrainSet_2$rp<=2) 

#Pre-processamento dos dados
# Apaga a coluna 
TrainSet_3$Val_pred = NULL
TrainSet_3$residuo = NULL
TrainSet_3$rp = NULL
```

### Rodar o modelo
```{r modelo4}
modelo3 <- lm(target ~ ., data = TrainSet_3)
summary(modelo3)
```

```{r previsao4}

TrainSet_3$Val_pred <- predict(modelo3) 
TrainSet_3$residuo  <- resid(modelo3)
TrainSet_3$rp <- rstandard(modelo3)

```

```{r analise4}
df_analise3 <- TrainSet_3 %>%
  select(target, Val_pred, residuo, rp)
```


```{r rmse4}
# Erro quadratico medio na amostra de treino
mse3 <- mean((TrainSet_3$target - TrainSet_3$Val_pred)^2)
sqrt(mse3)

```
### Análise dos resíduos do modelo

```{r residuo4}
plot(predict(modelo3),TrainSet_3$residuo, xlab = "Preditor linear",ylab = "Residuos")
abline(h = 0, lty = 2)

```
```{r normalidade4}
qqnorm(residuals(modelo3), ylab="Residuos",xlab="Quantis teoricos",main="")
qqline(residuals(modelo3))
```


##---------------------------------------------------------------------------------------
##                           AMOSTRA DE VALIDACAO
##---------------------------------------------------------------------------------------


```{r amostra_validacao}

# Amostra de validacao

target_pred <- predict(modelo2, interval = "prediction", level = 0.95,
                    newdata = ValidSet, se.fit = T) 

target_pred1 <-target_pred$fit
ValidSet_pred=cbind(ValidSet,target_pred1)
```


```{r residuo_validacao}
# Residuo na amostra de validacao
residuo_valid <- ValidSet_pred$target - ValidSet_pred$fit
hist(residuo_valid)
qqnorm(residuo_valid, ylab="Res?duos",xlab="Quantis te?ricos",main="")
qqline(residuo_valid)
```



```{r rmse_validacao}

# Erro quadratico medio na amostra de validacao
mse2 <- mean((ValidSet_pred$target - ValidSet_pred$fit)^2)
sqrt(mse2)
```
```{r}
library(ggplot2)

# Convertendo as previsões para um data.frame
pred_df <- as.data.frame(target_pred$fit)

# Adicionando a variável independente ou índice ao data.frame (se necessário)
# Substitua variavel_independente pelo nome da sua variável independente ou use um índice sequencial.
pred_df$x <- 1:7493

# Criando o gráfico com apenas as primeiras 10 previsões
ggplot(pred_df[0:50, ], aes(x = x, y = fit)) +
  geom_point(aes(y = ValidSet$target[0:50]), color = 'blue') + # Pontos dos dados reais
  geom_line(aes(y = fit), color = 'black') + # Linha dos valores ajustados
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.2) + # Área de intervalo de predição
  labs(x = "Variável Independente", y = "Target", title = "Valores Ajustados com Intervalo de Predição para as Primeiras 10 Observações")


```

```{r}
# Fazer previsões nos dados de validação
predictions <- predict(modelo3, newdata = novo_ValidSet)
```

```{r}
# Calculando o MSE
mse <- mean((novo_ValidSet$target - predictions)^2)

# Calculando o RMSE
rmse <- sqrt(mse)

# Calculando o MAE
mae <- mean(abs(novo_ValidSet$target - predictions))

# Imprimindo os resultados
cat("MSE:", mse, "\n")
cat("RMSE:", rmse, "\n")
cat("MAE:", mae, "\n")

# Calcular a soma dos quadrados dos resíduos (SS_res)
SS_res <- sum((novo_ValidSet$target - predictions)^2)

# Calcular a soma total dos quadrados (SS_tot)
SS_tot <- sum((novo_ValidSet$target - mean(novo_ValidSet$target))^2)

# Calcular o R² nos dados de validação
R2_validation <- 1 - (SS_res / SS_tot)

# Imprimir o R²
cat("R² nos dados de validação:", R2_validation, "\n")
```


